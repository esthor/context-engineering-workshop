# System Architecture - Context Engineering

## Visual Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RESOURCES                                 â”‚
â”‚  (Raw Data - Never all loaded at once)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Company    â”‚  â”‚   Reviewee   â”‚  â”‚   Manager    â”‚          â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚          â”‚
â”‚  â”‚ â€¢ Guidelines â”‚  â”‚ â€¢ Profile    â”‚  â”‚ â€¢ 1:1 Notes  â”‚          â”‚
â”‚  â”‚ â€¢ Framework  â”‚  â”‚ â€¢ Work       â”‚  â”‚ â€¢ Peer       â”‚          â”‚
â”‚  â”‚ â€¢ Levels     â”‚  â”‚   History    â”‚  â”‚   Feedback   â”‚          â”‚
â”‚  â”‚ â€¢ Calibrate  â”‚  â”‚              â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                   â”‚                   â”‚
            â–¼                   â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   AGENT 1     â”‚   â”‚   AGENT 2     â”‚   â”‚   AGENT 3     â”‚
    â”‚  Framework    â”‚   â”‚   Employee    â”‚   â”‚   Manager     â”‚
    â”‚               â”‚   â”‚               â”‚   â”‚               â”‚
    â”‚ Context: 2KB  â”‚   â”‚ Context: 4KB  â”‚   â”‚ Context: 5KB  â”‚
    â”‚ Output: 500T  â”‚   â”‚ Output: 800T  â”‚   â”‚ Output: 800T  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                   â”‚                   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   AGENT 4     â”‚
                        â”‚  Synthesis    â”‚
                        â”‚               â”‚
                        â”‚ Context: 2.1K â”‚   â† Only condensed
                        â”‚               â”‚     outputs, not
                        â”‚ Output: 2000T â”‚     raw resources!
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   AGENT 5     â”‚
                        â”‚   Reviewer    â”‚
                        â”‚               â”‚
                        â”‚ Context: 3.5K â”‚
                        â”‚ Output: 1500T â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ FINAL REVIEW  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY:
  KB = Kilobytes of context
  T  = Tokens in output
  â†’ = Data flow
```

## Information Flow

### Phase 1: Extraction (Parallel)
```
Resources â†’ Agent 1,2,3 â†’ Condensed Summaries
```
Each agent gets only its slice of resources. Agents 1-3 can run in parallel.

### Phase 2: Synthesis (Sequential)
```
Condensed Summaries â†’ Agent 4 â†’ Draft Review
```
Synthesis sees only the structured outputs from Phase 1, not raw resources.

### Phase 3: Quality Check (Sequential)
```
Draft Review + Framework â†’ Agent 5 â†’ Quality Report
```
Reviewer compares draft against framework for quality assurance.

## Context Window Comparison

### Traditional Approach
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ONE MASSIVE LLM CALL                    â”‚
â”‚                                                 â”‚
â”‚  Company Guidelines:           15,000 tokens    â”‚
â”‚  Employee Work History:        12,000 tokens    â”‚
â”‚  Manager Notes & Feedback:     18,000 tokens    â”‚
â”‚  Schema & Instructions:         5,000 tokens    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  TOTAL CONTEXT:                50,000 tokens    â”‚
â”‚                                                 â”‚
â”‚  Problems:                                      â”‚
â”‚  â€¢ Expensive (~$2.50 per review)                â”‚
â”‚  â€¢ Slow (30-60 second response)                 â”‚
â”‚  â€¢ May miss details in large context            â”‚
â”‚  â€¢ Hard to debug what went wrong                â”‚
â”‚  â€¢ Can't parallelize                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Context-Engineered Approach
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FIVE FOCUSED LLM CALLS                  â”‚
â”‚                                                 â”‚
â”‚  Agent 1 (Framework):           2,000 tokens    â”‚
â”‚  Agent 2 (Employee):            4,000 tokens    â”‚
â”‚  Agent 3 (Manager):             5,000 tokens    â”‚
â”‚  Agent 4 (Synthesis):           6,000 tokens    â”‚
â”‚  Agent 5 (Review):              4,000 tokens    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  TOTAL CONTEXT:                21,000 tokens    â”‚
â”‚                                                 â”‚
â”‚  Benefits:                                      â”‚
â”‚  â€¢ Cheaper (~$1.05 per review = 58% savings)    â”‚
â”‚  â€¢ Faster (parallel + smaller contexts)         â”‚
â”‚  â€¢ Focused attention on each task               â”‚
â”‚  â€¢ Easy to debug individual agents              â”‚
â”‚  â€¢ Agents 1-3 can run in parallel               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Agent Responsibilities

### ğŸ—ï¸ FrameworkAgent
**Purpose:** Extract and structure the performance review framework

**Input Resources:**
- `resources/company/training-materials/performance-review-guidelines.md`
- `resources/company/training-materials/calibration-guidelines.md`
- `resources/company/level-expectations.md`
- `resources/schema/schema.md`

**Prompt:** `prompts/extract-framework.md`

**Output:** Structured framework with:
- Evaluation dimensions
- Rating scale definitions
- Writing guidelines
- Level expectations

**Context Size:** ~2KB â†’ 500 tokens output

---

### ğŸ‘¤ EmployeeAgent
**Purpose:** Extract employee accomplishments and context

**Input Resources:**
- `resources/reviewee/employee-profile.md`
- `resources/reviewee/work-history-h2-2024.md`

**Prompt:** `prompts/extract-employee-context.md`

**Output:** Factual summary with:
- Major accomplishments with metrics
- Collaboration examples
- Skills demonstrated
- Challenges faced
- Career goals

**Context Size:** ~4KB â†’ 800 tokens output

---

### ğŸ’¼ ManagerAgent
**Purpose:** Extract manager insights and peer feedback

**Input Resources:**
- `resources/manager/1on1-notes-h2-2024.md`
- `resources/manager/peer-feedback.md`

**Prompt:** `prompts/extract-manager-insights.md`

**Output:** Qualitative insights with:
- Performance themes (strengths & development areas)
- Standout stories
- Peer feedback summary
- Growth trajectory
- Contextual factors

**Context Size:** ~5KB â†’ 800 tokens output

---

### ğŸ”„ SynthesisAgent
**Purpose:** Synthesize complete performance review

**Input:** Condensed outputs from Agents 1-3 (NOT raw resources!)

**Prompt:** `prompts/synthesize-review.md`

**Output:** Complete performance review with:
- Overall summary and rating
- Evaluation by dimension
- Key achievements
- Development areas with recommendations
- Goals for next period

**Context Size:** ~2KB condensed â†’ 2000 tokens output

---

### âœ… ReviewerAgent
**Purpose:** Quality check the draft review

**Input:**
- Draft review from SynthesisAgent
- Framework from FrameworkAgent

**Prompt:** `prompts/review-quality-check.md`

**Output:** Quality assessment with:
- Pass/Needs Revision decision
- Issues identified
- Specific recommendations
- Alignment checklist

**Context Size:** ~4KB â†’ 1500 tokens output

---

## Key Design Principles

### 1. Minimal Context Per Agent
Each agent sees only what it needs. No agent processes all raw resources.

### 2. Progressive Condensation
```
Raw Resources (50KB)
    â†“
Agent Summaries (2.1KB)
    â†“
Synthesis (2KB context)
    â†“
Final Review
```

### 3. Single Responsibility
Each agent has one clear job. Easy to test, debug, and improve.

### 4. Parallelization
Agents 1-3 are independent and can run concurrently.

### 5. Separation of Concerns
- **Resources:** Raw data storage
- **Prompts:** Task instructions
- **Agents:** Execution logic
- **Orchestrator:** Coordination

### 6. Debuggability
Each agent's input and output can be inspected independently.

## Cost & Performance Analysis

Based on GPT-5.1-nano (highly optimized nano model):

### Traditional Single-Call Approach
- Input: ~50,000 tokens
- Output: ~2,000 tokens
- **Total context: 50,000 tokens**
- Latency: 30-60 seconds (serial)

### Context-Engineered Multi-Agent Approach
- Agent 1: 2K input + 0.5K output
- Agent 2: 4K input + 0.8K output
- Agent 3: 5K input + 0.8K output
- Agent 4: 2K input + 2K output
- Agent 5: 4K input + 1.5K output
- **Total context: ~21,000 tokens**
- Latency: 15-30 seconds (with parallelization)

**Savings: 58% token reduction + 40-50% faster**

## Extensibility

This architecture makes it easy to:

1. **Add new agents:** Just create a new agent class with its prompt
2. **Modify behavior:** Update individual prompts without touching others
3. **Add resources:** Drop new files in resources/ and update relevant agent
4. **Change LLM:** Swap out LLM client without changing agent logic
5. **Add caching:** Cache agent outputs to avoid re-processing
6. **Scale:** Process multiple employees in parallel

## Testing Strategy

Each component can be tested independently:

```python
# Test individual agent
agent = FrameworkAgent()
context = agent.get_context()
assert "evaluation dimensions" in context.lower()

# Test agent output format
output = agent.run(mock_llm)
assert "Technical Excellence" in output

# Test orchestrator pipeline
orchestrator = PerformanceReviewOrchestrator(mock_llm)
result = orchestrator.generate_review()
assert result['metadata']['total_tokens'] < 25000
```

## Conclusion

This architecture demonstrates that **context engineering** isn't just about writing better promptsâ€”it's about designing systems that:

1. Minimize context through specialization
2. Process information progressively
3. Maintain debuggability and testability
4. Scale efficiently
5. Produce consistent quality

**The whole system is greater than the sum of its prompts.**
